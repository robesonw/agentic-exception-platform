# Agentic Exception Processing Platform - Environment Variables
# Copy this file to .env and update with your actual values
# DO NOT commit .env to version control

# =============================================================================
# Phase 6: Database Configuration (Required)
# =============================================================================

# Database Connection URL
# Format: postgresql+asyncpg://user:password@host:port/database
# If DATABASE_URL is set, it takes precedence over individual DB_* variables below
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/sentinai

# Alternative: Individual database connection components
# (Used only if DATABASE_URL is not set)
# DB_USER=postgres
# DB_PASSWORD=your_password_here
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=sentinai

# Database Connection Pool Settings
# pool_size: Number of connections to maintain in the pool
DB_POOL_SIZE=5

# max_overflow: Maximum number of connections to create beyond pool_size
DB_MAX_OVERFLOW=5

# pool_timeout: Seconds to wait before giving up on getting a connection from the pool
DB_POOL_TIMEOUT=30

# echo: Enable SQL query logging (useful for debugging, disable in production)
# Set to "true", "1", or "yes" to enable
DB_ECHO=false

# =============================================================================
# Phase 3: LLM Configuration (Optional)
# =============================================================================

# LLM Provider Configuration
# Supported providers: dummy, openai, anthropic, grok, groq
# Uncomment ONE provider section below based on your preference

# -----------------------------------------------------------------------------
# Option 1: Dummy Provider (Default - No API key required)
# -----------------------------------------------------------------------------
# Uses mock responses for testing. No real LLM calls made.
# Note: Mock embeddings don't provide semantic similarity - only exact matching
LLM_PROVIDER=dummy

# -----------------------------------------------------------------------------
# Option 2: OpenAI (Recommended for production)
# -----------------------------------------------------------------------------
# Models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Embeddings: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Get API key: https://platform.openai.com/api-keys
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4-turbo
# OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# Option 3: Anthropic (Claude)
# -----------------------------------------------------------------------------
# Models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# Get API key: https://console.anthropic.com/
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# -----------------------------------------------------------------------------
# Option 4: Grok (xAI)
# -----------------------------------------------------------------------------
# Models: grok-beta, grok-2
# Get API key: https://console.x.ai/
# LLM_PROVIDER=grok
# LLM_MODEL=grok-beta
# GROK_API_KEY=xai-your-grok-api-key-here

# -----------------------------------------------------------------------------
# Option 5: Groq (FREE tier available - Great for development!)
# -----------------------------------------------------------------------------
# Models: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
# Free tier: 14,400 requests/day for most models
# Get API key: https://console.groq.com/keys
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile
# GROQ_API_KEY=gsk_your-groq-api-key-here

# -----------------------------------------------------------------------------
# Advanced: OpenRouter (Access multiple providers with one API key)
# -----------------------------------------------------------------------------
# Provides access to OpenAI, Anthropic, Google, Meta models via single API
# Get API key: https://openrouter.ai/keys
# LLM_PROVIDER=openrouter
# LLM_MODEL=anthropic/claude-3-sonnet
# OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here

# =============================================================================
# API Configuration (Optional)
# =============================================================================

# API Server Configuration
# API_HOST=0.0.0.0
# API_PORT=8000

# =============================================================================
# Development/Testing Configuration
# =============================================================================

# For local development, use the defaults above
# For CI/CD, override with test database settings (see docs/configuration.md)
